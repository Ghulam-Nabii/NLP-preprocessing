{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aaljpVvlzsG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "with open('/content/drive/MyDrive/GenAI_Wksp/Sentiment_Classification/data/reviews.txt', 'r') as f:\n",
        "  reviews = f.read()\n",
        "\n",
        "with open('/content/drive/MyDrive/GenAI_Wksp/Sentiment_Classification/data/labels.txt', 'r') as f:\n",
        "  labels = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviews[:1000])\n",
        "print()\n",
        "print(labels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcl92pDcmrqc",
        "outputId": "f85d1d22-6664-4590-ac20-15a70a125802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turn\n",
            "\n",
            "positive\n",
            "n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "reviews = reviews.lower()\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "\n",
        "reviews_split = all_text.split('\\n')\n",
        "all_text = ' '.join(reviews_split)\n",
        "all_words = all_text.split()\n",
        "\n"
      ],
      "metadata": {
        "id": "ml5ac4WRm3Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_split = labels.split('\\n')\n",
        "encoded_labels = np.array([1 if label =='positive' else 0 for label in labels_split])"
      ],
      "metadata": {
        "id": "WIROWcWyn_eq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "review_lens = Counter([len(x.split()) for x in reviews_split])\n",
        "print(\"Zero lenght : {}\".format(review_lens[0]))\n",
        "print(\"Max lenght : {}\".format(max(review_lens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPCZzdN0o6b1",
        "outputId": "767cc29a-1d84-4c0f-b002-cb82d600d17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero lenght : 1\n",
            "Max lenght : 2514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_zero_idx = [ii for ii, review in enumerate(reviews_split) if len(review.split()) != 0]\n",
        "\n",
        "reviews_split = [reviews_split[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])"
      ],
      "metadata": {
        "id": "9q6P-fi2qGem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "embed_lookup = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/GenAI_Wksp/Sentiment_Classification/word2vec_model/GoogleNews-vectors-negative300-SLIM.bin',\n",
        "                                                 binary=True)"
      ],
      "metadata": {
        "id": "5l3wJErLqJWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_words =[]\n",
        "for index, word in enumerate(embed_lookup.index_to_key):\n",
        "  pretrained_words.append(word)"
      ],
      "metadata": {
        "id": "rgCsfsoWs0oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_all_reviews(embed_lookup, reviews_split):\n",
        "    reviews_words = [review.split() for review in reviews_split]\n",
        "\n",
        "    tokenized_reviews = []\n",
        "    for review in reviews_words:\n",
        "        ints = []\n",
        "        for word in review:\n",
        "            try:\n",
        "                idx = embed_lookup.key_to_index[word]\n",
        "            except:\n",
        "                idx = 0\n",
        "            ints.append(idx)\n",
        "        tokenized_reviews.append(ints)\n",
        "\n",
        "    return tokenized_reviews\n",
        "\n"
      ],
      "metadata": {
        "id": "P-LWU2iZuQok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews = tokenize_all_reviews(embed_lookup, reviews_split)\n",
        "print(tokenized_reviews[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjlYA5GGwdKO",
        "outputId": "b6231853-d22a-4612-81ff-0f4e410c308c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 137, 3, 0, 11620, 3799, 13, 1215, 10, 9, 194, 54, 12, 73, 61, 685, 41, 183, 243, 129, 12, 1663, 119, 72, 0, 9, 2989, 7334, 242, 159, 0, 453, 2, 0, 137, 1239, 19951, 3, 141, 1980, 0, 1898, 55, 3, 1663, 9, 11124, 0, 3857, 6663, 9, 20401, 295, 28, 45, 148, 157, 102, 27, 15452, 1663, 30714, 9, 65172, 0, 9, 844, 737, 47, 6585, 159, 0, 9, 668, 4365, 1003, 0, 27, 295, 56, 4365, 622, 9, 3832, 0, 43, 0, 897, 3187, 907, 0, 5396, 113, 9, 183, 4365, 1009, 3165, 10, 137, 0, 3288, 296, 10314, 4365, 6638, 213, 0, 8810, 40, 0, 116, 1663, 897, 2059, 0, 0, 137, 4365, 830, 2, 124, 2216, 0, 119, 782, 144, 2, 0, 137, 3, 330, 23046, 78, 0, 16915, 2, 13, 85275, 7451]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_features(tokenized_reviews, seq_length):\n",
        "    features = np.zeros((len(tokenized_reviews), seq_length), dtype=int)\n",
        "    for i, row in enumerate(tokenized_reviews):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "5i2DOZfzw6_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequecne_length = 200\n",
        "features = pad_features(tokenized_reviews, seq_length=sequecne_length)\n",
        "\n",
        "print(features[:10,:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLSjePNNxWoK",
        "outputId": "6cb97ba3-b8c4-464d-e088-2ede8c58077e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [ 16483     26      0     12 106210      0   1698     22     37     24\n",
            "     432      1     72     30    275      0    303      0    162    126]\n",
            " [  1935   1326     12      0   1403     60   3921   2019      3   4809\n",
            "      36      6   3172   7184    129   7951      0   2180   6098 166268]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [    56   4365      8    270    119    756    247    159    381      0\n",
            "       9   2669      0    148  21621     13      8     40      0    124]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_frac = 0.8 #80% Training data      20% Test Data\n",
        "split_idx = int(len(features)*0.8)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lfr56MMRx4HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "val_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "QZcbcirl2K-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UaGbHnE20IP",
        "outputId": "010e2064-c6c7-404f-ab59-4f129e7eb330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SentimentCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The embedding layer + CNN model that will be used to perform sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_model, vocab_size, output_size, embedding_dim,\n",
        "                 num_filters=100, kernel_sizes=[3, 4, 5], freeze_embeddings=True, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentCNN, self).__init__()\n",
        "\n",
        "        self.num_filters = num_filters\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.embedding.weight = nn.Parameter(torch.from_numpy(embed_model.vectors)) # all vectors\n",
        "\n",
        "        if freeze_embeddings:\n",
        "            self.embedding.requires_grad = False\n",
        "\n",
        "        self.convs_1d = nn.ModuleList([\n",
        "            nn.Conv2d(1, num_filters, (k, embedding_dim), padding=(k-2,0))\n",
        "            for k in kernel_sizes])\n",
        "\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * num_filters, output_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def conv_and_pool(self, x, conv):\n",
        "\n",
        "        x = F.relu(conv(x)).squeeze(3)\n",
        "\n",
        "\n",
        "        x_max = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "        return x_max\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines how a batch of inputs, x, passes through the model layers.\n",
        "        Returns a single, sigmoid-activated class score as output.\n",
        "        \"\"\"\n",
        "        embeds = self.embedding(x) # (batch_size, seq_length, embedding_dim)\n",
        "        embeds = embeds.unsqueeze(1)\n",
        "\n",
        "        conv_results = [self.conv_and_pool(embeds, conv) for conv in self.convs_1d]\n",
        "\n",
        "        x = torch.cat(conv_results, 1)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logit = self.fc(x)\n",
        "\n",
        "        return self.sig(logit)\n"
      ],
      "metadata": {
        "id": "-JzKNrYe3H9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(pretrained_words)\n",
        "output_size = 1 # binary class (1 or 0)\n",
        "embedding_dim = len(embed_lookup[pretrained_words[0]]) # 300-dim vectors\n",
        "num_filters = 50\n",
        "kernel_sizes = [3, 4, 5]\n",
        "\n",
        "net = SentimentCNN(embed_lookup, vocab_size, output_size, embedding_dim,\n",
        "                   num_filters, kernel_sizes)\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5_yJdcwq0Ya",
        "outputId": "eb34b0d2-5028-431a-fa95-52c56ec8d18b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentCNN(\n",
            "  (embedding): Embedding(299567, 300)\n",
            "  (convs_1d): ModuleList(\n",
            "    (0): Conv2d(1, 50, kernel_size=(3, 300), stride=(1, 1), padding=(1, 0))\n",
            "    (1): Conv2d(1, 50, kernel_size=(4, 300), stride=(1, 1), padding=(2, 0))\n",
            "    (2): Conv2d(1, 50, kernel_size=(5, 300), stride=(1, 1), padding=(3, 0))\n",
            "  )\n",
            "  (fc): Linear(in_features=150, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.0001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n"
      ],
      "metadata": {
        "id": "_41ZcgITscSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_loader, epochs, print_every=100):\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    net.train()\n",
        "    for e in range(epochs):\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            counter += 1\n",
        "\n",
        "            if(train_on_gpu):\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            net.zero_grad()\n",
        "\n",
        "            output = net(inputs)\n",
        "\n",
        "            loss = criterion(output.squeeze(), labels.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if counter % print_every == 0:\n",
        "                val_losses = []\n",
        "                net.eval()\n",
        "                for inputs, labels in valid_loader:\n",
        "\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                    output = net(inputs)\n",
        "                    val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                net.train()\n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "metadata": {
        "id": "0NZsLogKtjtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "print_every = 100\n",
        "train(net, train_loader, epochs, print_every=print_every)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWkrwGXwx6_7",
        "outputId": "ad436474-d09f-44db-8713-c41cb7e161d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5... Step: 100... Loss: 0.686637... Val Loss: 0.685606\n",
            "Epoch: 1/5... Step: 200... Loss: 0.666189... Val Loss: 0.667301\n",
            "Epoch: 2/5... Step: 300... Loss: 0.612791... Val Loss: 0.612809\n",
            "Epoch: 2/5... Step: 400... Loss: 0.493318... Val Loss: 0.534121\n",
            "Epoch: 3/5... Step: 500... Loss: 0.386140... Val Loss: 0.485331\n",
            "Epoch: 3/5... Step: 600... Loss: 0.456306... Val Loss: 0.456960\n",
            "Epoch: 4/5... Step: 700... Loss: 0.381377... Val Loss: 0.434691\n",
            "Epoch: 4/5... Step: 800... Loss: 0.516579... Val Loss: 0.418425\n",
            "Epoch: 5/5... Step: 900... Loss: 0.342584... Val Loss: 0.406925\n",
            "Epoch: 5/5... Step: 1000... Loss: 0.326070... Val Loss: 0.394782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "\n",
        "net.eval()\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    output = net(inputs)\n",
        "\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT3P21M_04Fr",
        "outputId": "2e1fe517-2ae9-40d9-ed9a-db6771595e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.413\n",
            "Test accuracy: 0.815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(embed_lookup, test_review):\n",
        "    test_review = test_review.lower() # lowercase\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    test_words = test_text.split()\n",
        "    print(test_words)\n",
        "    tokenized_review = []\n",
        "    for word in test_words:\n",
        "        try:\n",
        "            idx = embed_lookup.key_to_index[word]\n",
        "        except:\n",
        "            idx = 0\n",
        "        tokenized_review.append(idx)\n",
        "\n",
        "    return tokenized_review\n"
      ],
      "metadata": {
        "id": "bM1RzQvw2Mm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(embed_lookup, net, test_review, sequence_length=200):\n",
        "    \"\"\"\n",
        "    Predict whether a given test_review has negative or positive sentiment.\n",
        "    \"\"\"\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    test_ints = tokenize_review(embed_lookup, test_review)\n",
        "    print(test_ints)\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features([test_ints], seq_length)\n",
        "\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "\n",
        "    batch_size = feature_tensor.size(0)\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "\n",
        "    output = net(feature_tensor)\n",
        "\n",
        "    pred = torch.round(output.squeeze())\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "\n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review detected!\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")\n"
      ],
      "metadata": {
        "id": "TOoIAqTx2QXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=200"
      ],
      "metadata": {
        "id": "W6e708Ia2vWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_review_pos = 'worst Movie i have ever seen.'\n",
        "predict(embed_lookup, net, test_review_pos, seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7BbARcq2wj4",
        "outputId": "dc000dbd-4ca9-453c-f4ec-d9325008312a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['worst', 'movie', 'i', 'have', 'ever', 'seen']\n",
            "[1398, 1083, 4365, 19, 491, 441]\n",
            "Prediction value, pre-rounding: 0.012376\n",
            "Negative review detected.\n"
          ]
        }
      ]
    }
  ]
}